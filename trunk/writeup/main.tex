\begin{abstract}
\input{abstract}
\end{abstract}

\section{Introduction}

Over the past couple of decades, many sophisticated type systems and,
more generally, program analyses have been developed, allowing
complex, important properties of software to be verified. Advances in
type inference, dataflow analysis, and constraint solving have made
programming with such verification more practical, by lowering the
annotation burden and making verification time more acceptable.  Use
of these techniques has become more common, but expressive type
systems are still infrequently used.

We posit that a key barrier to adoption of these sophisticated
analyses is the difficulty of debugging programs when the analysis
reports an error. Because deep, non-local software properties are
being checked, the analysis may detect an inconsistency in a part of
the program that is far from the actual error. Reporting on the
inconsistency at the point of detection can result in a misleading
error message. Determinining where the true error lies based on this
error message can require excessive effort from the programmer, and an
unreasonably high degree of understanding of how the analysis works
in order to interpret the error report.

We are motivated to study this problem based on experience with two
programming languages with a reputation for difficult-to-interpret
error messages: ML, whose unification-based type inference algorithm
sometimes generates complex, even misleading error
messages~\cite{wand-errorfinding}, and Jif~\cite{jif}, a version of
Java that statically analyzes the security of information flow within
programs but whose errors also confuse programmers~\cite{king:fse}.
Prior work has explored a variety of methods for improving the errors
reported by each of these languages. However, these methods are often
specialized to the respective languages.

In this work we take a more generic approach to diagnosing the errors
generated by program analyses.  To make the approach generic, we
observe that most program analyses, type inference algorithms, and
type systems can be phrased as constraint-solving problems in which a
system of constraints over variables is to be solved to find values
for the variables.  A system of constraints can be generated from
these various analyses and solved in a generic way by a constraint
solver. For example, in the case of ML type inference, variables
stand for types, and constraints are equalities between different
type expressions mentioning these variables. When the constraint
system is unsatisfiable, the constraint solver at some point
determines there is no way to satisfy some particular constraint. The
question is then how to report this failure, indicating a program
error, to the user. Current practice involves mapping the constraint
back to the program point that generated it, and reporting a
corresponding message. Unfortunately, the actual error in the program
text may be located far from the code that generated the failed
constraint, causing misleading error messages.

Our insight is that when the constraint system is unsatisfiable, a
more holistic approach should be taken to deciding where the program
error is likely to be found. Rather than just looking at the failed
constraint in isolation, the structure of the constraint system as
a whole should be considered. Both satisfiable and unsatisfiable
paths through the constraint system may yield valuable information
about where the error is located.  An expression that is involved
in many unsatisfiable paths is more likely to be erroneous, whereas
an expression that lies on many satisfiable paths is more likely to
be correct. This approach to identifying errors can be
justified on maximum a posteriori principles, under the assumption
that programmers write code that is mostly correct.

In many languages, the satisfiability of constraint systems may depend
on environmental assumptions (or hypotheses). The conceptual framework
for identifying likely errors can also be applied to identifying likely
missing hypotheses. Again, programmers are not likely to have omitted
many hypotheses, so a small set of hypotheses that makes the constraint
satisfiable is more likely to be correct than a larger set or a large
set of erroneous expressions.
%Recent work on abductive inference~\cite{dillig:pldi12} has studied
%inferring missing hypotheses but has 

\paragraph{Contributions}

This paper makes the following contributions:

\begin{enumerate}
\item
A general constraint language that can model a broad
range of program analyses. It can encode both ML type
inference and Jif information flow analysis
(Section~\ref{sec:language}).

\item
A general algorithm for identifying likely program errors,
based on an analysis of the constraint system corresponding
to the program. This algorithm proposes both program expressions
that are likely to be errors, based on maximum a posteriori
principles, and also hypotheses that the programmer is
deemed likely to have omitted. Importantly, the algorithm
requires little language-specific tuning to generate good results.
(Sections~\ref{sec:graph} and~\ref{sec:ranking}.)

\item
An evaluation of this new error diagnosis algorithm on two
different sets of programs, including a large set of programs
collected from students using OCaml to do
programming assignments~\cite{lerner:pldi07}
(Section~\ref{sec:evaluation}.)

\end{enumerate}

\section{Program analyses and constraint solving}

%Many program analyses can be modeled as constraint solving problems. In this
%section, we use two apparently different kinds of analyses, information-flow
%control and ML-like language type inference, to motivate why error diagnostic
%is difficult and illustrate the main approach of our work.

\section{Constraint language}
\label{sec:language}

A key component of our approach is a general core constraint language
that can be used to capture a large class of program analyses.
In this constraint language, constraints are inequations using an
operator ≤ corresponding
to a flow of information through a program. The constraint language
also supports constructors and destructors corresponding to
computation.
%How information flow control and ML-like type
%inference can be expressed by this language is also discussed. 

\subsection{Syntax}

The syntax of the constraint language is formalized in
Figure~\ref{figure:lang:syntax}.

\begin{figure}
\hfil
\begin{minipage}{2in}
\begin{align*}
G &::= G_1 \land G_2 \bnf A \\
A &::= C_1 \proves C_2 \\
C &::= I_1 \land ... \land I_n~~^{n≥0} \\
I &::= E_1 ≤ E_2 \\
E &::= x \bnf c(E_1,\dots,E_{\arity{c}}) \bnf \invcabs{c}{i}(E) \\
  & \bnf E_1 \join E_2 \
\bnf E_1 \meet E_2 \bnf \bot \bnf \top
\end{align*}
\end{minipage}
\hfil
\caption{Syntax of constraints}
\label{figure:lang:syntax}
\end{figure}

The top-level goal $G$ to be solved is a conjunction of assertions $A$. An
assertion has the form of $C_1 \proves C_2$, where constraint $C_1$ is the
hypothesis and constraint $C_2$ is a conclusion to be satisfied.
 
Constraint $C$, either serving as the hypothesis or the conclusion, is a
possibly empty conjunction of inequations $I$ over elements from $E$,
based on some ordering $≤$. We denote an empty conjunction as ∅.
We abbreviate $∅ \proves C_2$ as $\proves C_2$

An element $E$ may be a variable $x\in\varset$ whose value is to be
solved for, a constructor application $c$ or the $i$-th projection
($i$-th component) of a constructor application, represented by
$\invcabs{c}{i}(E)$. The arity of constructor $c$ is represented
as $a(c)$.  For example, if modeling ML type inference, we would
represent the type "int->bool" as a constructor application
$\cons{arrow}{\atom{int}, \atom{bool}}$, where $\atom{int}$
and $\atom{bool}$ are themselves nullary constructor applications.
Its first projection $\invc{arrow}{1}
(\cons{arrow}{\atom{int}, \atom{bool}})$ is equal to $\atom{int}$.
%
Elements can also be the join ($\join$) or meet ($\meet$) of elements.
The bottom and top of the element ordering are 
$\bot$ and $\top$.
%When join and meet are
%used, we assume for all $e_1, e_2 \in E, e_1 \join e_2 \in E \land e_1
%\meet e_2 \in E$ to make the constraints well-formed. In another word,
%the elements form a lattice.

\subsection{Interpretation of constraints}

The ordering $\leq$ is treated abstractly by our diagnosis algorithm,
but it must define a lattice. The operators $\join$ (join) and $\meet$
(meet) produce the least upper bound and greatest lower bound
of their operands, respectively.
%
The elements $\bot$ and $\top$ are respectively the least and greatest
element with respect to $\leq$.

We further assume that the partial ordering on constructor applications
is determined by the polarities of that constructor's arguments.
For each argument, the ordering of the constructor is either
covariant with respect to that argument, contravariant with respect
to that argument, or invariant with respect to that argument.
%That is, $\forall c\in \conset, c(E_1, \dots, E_{a(c)})\leq c(E_1',
%\dots, E_{a(c)}') \Iff E_1\leq E_1' \land \dots, E_{a(c)}\leq
%E_{a(c)}'$.

With these abstract definitions, the _validity_ of constraints can be defined
in a natural way: an assertion $C_1 \proves C_2$ is _valid_ if and only if all
the partial orderings in $C_2$ can be inferred from $C_1$, giving the abstract
meaning of the operations defined so far.

Consequently, a goal $G$ is valid if all assertions it contains are valid.

\paragraph{Example}

Let $c_1, c_2, c_3$ be three constants. Then $c_1 \leq c_2 \land c_2 \leq c_3
\proves c_1 \leq c_3$ is valid by the transitivity of $\leq$. Assertion $
\proves c_1 \leq c_1 \join c_2$ is valid by the definition of join. But
assertion $\proves c_1\leq c_2$ is invalid since the
conclusion cannot be inferred from the empty assumption.

\subsection{Satisfiability}

Validity as defined so far works for constraints without variables. In
general, when variables are involved, we want to know whether there
exists a valuation of all variables such that the goal after value
substitution is valid or not. This is formalized as _satisfiability_
of constraints.

Satisfiability depends on the _ground terms_ $\termset$ that a
variable can map into. We define $\termset$ as the greatest fixed
point of the following rules:

\begin{itemize}
\item All constants are in $\termset$.

\item $c(t_1, \dots, t_{\arity{c}})\in \termset$ if 
$\forall{i∈\{1,\dots,a(c)\}}~t_i\in \termset$ and $c\in C$.
\end{itemize}

\noindent
Notice that ground terms may have infinite representations. This feature is
essential in modeling recursive types.

% All terms form a Herbrand universe under $\join$ and $\meet$.

A valuation $\valuation: \varset→\termset$ is a function from
variables to terms. A goal is _satisfiable_ when there exists a
valuation such that the goal after the substitution is valid. 

\paragraph{Example}

Let $x\in \varset$, $c_1, c_2, c_3\in \termset$. Then $\proves x \leq c_1$ is
trivially satisfiable considering the valuation $\valuation(x)=c_1$ or
$\valuation(x)=\bot$. However, $\proves x \leq c_1 \land c_2 \leq x$ is
unsatisfiable since otherwise, $c_2 \leq c_1$ by the transitivity of $\leq$.
But such partial order on $c_1, c_2$ is nowhere to be inferred.

The terms can have infinite representations. For instance, $\proves x
\leq \cons{\textit{c}}{\atom{zero}, x}$, where $\atom{zero} \in
\conset \land a(\atom{zero})=1$ and $x\in \varset$ is satisfiable by
replacing $x$ with $c(\atom{zero}, c(\atom{zero}, \dots))$.    
\ACM{This seems broken. a(zero) = 0, right? and a(c) = 2?}

\subsection{Error diagnostic}

Recall that the goal of this work is to diagnose the cause of errors.
Therefore we are primarily interested not in the satisfiability of a
set of assertions, but in where to place the blame when
a goal is unsatisfiable. The goal is to find the most plausible
explanation for the failure of satisfiability. In our approach,
an explanation consists of a subset of elements from the constraint
system, constraints from the constraint system, and possibly some
missing hypotheses. Under the assumption that programmers write
mostly correct code, the more plausible explanations are those that
involve the fewest programmer errors.

\paragraph{Incorrect constraints}

One cause of unsatisfiability the is the existence of some constraints
in the goal's conclusions. We say that a set of constraints
$\mathcal{C}$ is _inconsistent_ if removing those constraints from
goal conclusions make an unsatisfiable goal satisfiable.

\paragraph{Example}

Consider the unsatisfiable goal $\proves x \leq c_1 \land c_2 \leq x$
again. Another possible cause of the unsatisfiability may be that one
of the constraints $x \leq c_1$ and $c_2 \leq x$ is wrong. 

\paragraph{Missing hypotheses}

A second cause of unsatisfiability is the absence of constraints in
the hypothesis. Such error corresponds to the failure to write down
assumptions.

A missing hypothesis is defined in the following way.
Given an unsatisfiable goal $C_{11} \proves C_{12} \land C_{21} \proves C_{22}
\land \dots \land C_{n1} \proves C_{n2}$, a constraint $C$ is a _missing
hypothesis_ if and only if $C_{11} \land C \proves C_{12} \land C_{21} \land C
\proves C_{22} \land \dots \land C_{n1} \land C \proves C_{n2}$ is
satisfiable~\footnote{This definition is an estimation of a more general form
of missing hypothesis, namely a vector of $(C_1', C_2', \dots, C_n')$ such that
$C_{11} \land C_1' \proves C_{12} \land C_{21} \land C_2' \proves C_{22} \land
\dots \land C_{n1} \land C_n' \proves C_{n2}$. But it is less feasible to
calculate the missing assumptions based on this definition. We will discuss in
more detail in Section~\ref{sec:assumptions}}.

\paragraph{Example}
Consider the unsatisfiable goal $\proves x \leq c_1 \land c_2 \leq x$.
One possible cause of the unsatisfiability may be the missing of an
hypothesis $c_1\leq c_2$.

\paragraph{Relation with set constraints}

Although the core constraint language we propose is similar to set
constraints~\cite{aiken-setconstraint} in spirit, there are several
noticeable differences:

\begin{enumerate}

\item Most importantly, hypotheses is modeled in our language. This extended
expressiveness enabled the modeling of some real-world program analyses, such
as the ``where'' clause in Jif and the subtyping relationship in many
object-oriented systems. 

\item We exclude the negation of elements in our model since it is not
essential in modeling many program analyses. Also, previous work showed that
the complexity of solving the full set of set constraints is NP to
NEXPTIME~\cite{aiken-complexity}. We believe that the constraint language we
proposed in this work is both expressive and practical for real-world program
analyses.

\end{enumerate}

\subsection{Expressiveness}

% Due to the similarity between our core constraint language and set
% constraint, the applications modeled by the later without negations
% are automatically expressed by our model. Such examples includes type
% inference with sum type and product type and closure analysis.

In this part, we discuss how information-flow control and ML type inference
with polymorphism can be expressed by our constraint language.

\subsubsection{Information-flow control}

In information-flow control systems, information is tagged with security
labels, such as labels from unclassified to top secret. More generally, the
security labels in nature forms a lattice~\cite{denning-lattice}. The goal of
such systems is to restrict insecure flows from information to a place with
less restrictive labels, such as from top secret to unclassified. 

% The security labels can be modeled by the constants in our constraint language.
% $\leq$ is interpreted as ``less restrictive'' in this problem domain. The join
% and meet operations in constraints are consistent with that in the lattice.
% $\bot$ is the most public label, while $\top$ corresponds to the most
% restrictive one. 

In this part, we focus on a sophisticated information-flow control model, the
DLM model~\cite{ml-ifc-97}, due to the following challenging features. Of
course, models with less intricacy can also be described by our core constraint
language.

\begin{enumerate}
\item The label model is more complicated than traditional multilevel security
system.

\item DLM introduces an implicit form of parametric polymorphism, called _label
polymorphism_, to express procedures that are parametric with respect to the
security labels of their arguments.

\item DLM allows assertions on labels to enable the combination of a static
program analysis provably enforces security under some assumptions, while the
validity of the assumptions are enforced at runtime. 
\end{enumerate}

\paragraph{Label model}

The basic building block of the DLM model is a set of _principals_ representing
users and other authority entities. Examples of principals could be patient A,
patient B, doctor A and so on. 

Principals are structured as a lattice with respect to a relation _actsfor_.
$actsfor(A,B)$ means that $A$ is more privileged than $B$.
% 
For instance, if doctor A _actsfor_ patient A, then doctor A is allowed to read
all information that patient A can read. However, such relation does not grant
doctor A to read any information patient B can read, unless doctor A _actsfor_
patient B too.

The security concern of information is expressed by _labels_. A label $L$
contains a set of principals called the _owners_. For each owner $O$, the label
also contains a set of principals called the _readers_. Readers are the
principals owner $O$ is willing to release the information. 

For instance, a label $\{o_1:r_1,r_2;\ o_2:r_2,r_3\}$ can be read as: principal
$o_1$ allows principals $r_1$ \emph{or} $r_2$ to read the tagged information,
\emph{and} principal $o_2$ allows principals $r_2$ \emph{or} $r_3$ to read.
Hence effectively, the _effective reader set_ is the intersection of the
readers of all owners. That is $\{r_2\}$ in this example.

The partial order on labels can be complicated by the _actsfor_ relationship of
principals.

 
\paragraph{ML-like type inference}

Type inference can also naturally map into constraint solving. This
view is not new. For instance, Wand~\cite{wand-typeinference} recast
Hindley-Milner type system into equality constraints. Aiken and
Wimmers~\cite{aiken-typeinclusion} extends the Hindley-Milner type
system with inclusion constraints, and models function types,
constructor types, liberal intersection and union types. 

For simplicity, we discuss how the type inference of a subset
(including let polymorphism) of ML-like language can be transformed
into _labeled constraints_~\cite{haack:slicing}, a subset of our
constraint language.

In this setting, types are the elements. Join and
meet operations are the usual intersection and union types if that is
well defined.
$\leq$ is consistent with the subtype relationship between two labels.
Since the definition is abstract, both syntactic subtyping \DZ{REF}
and semantic subtyping~\cite{aiken-typeinclusion} fit in this model.

For type inference:

Type inference is reduced to constraint solving by defining a mapping
of _pre-judgements_to constraints:
\[\trans{\G \proves x:\tau} = x =\tau\]
\[\trans{\G \proves \lambda x.e:\tau} = \exists a_1 a_2.
(def x: a_1 in \trans{e:a_2} \land a_1 \rightarrow a_2 =\tau)\]
\[\trans{\G\proves e_1 e_2 : \tau} = \exists a.(\trans{\G \proves
e_1:a\rightarrow \tau}\land \trans{\G\proves e_2:a})\]

\DZ{We may eliminate the 'exists' by creating fresh variables}

\paragraph{Polymorphic Types}

Our model is also powerful enough to capture polymorphic types.  Jif
has polymorphic types, for instance, $caller\_pc$. Polymorphic types
are also crucial for ML-like languages.

Polymorphic types can be naturally modeled in our core constraint
language as follows. For a polymorphic type $t$ instance, we create a
new constant $c_t$ and replace all occurrences of $t$ with $c_t$ in
the constraints. This is sufficient since the semantics of a
polymorphic type is that the constraints should be satisfied
regardless of the value of $t$. For instance, $t\leq \top$ where $t$
is a polymorphic type is satisfiable.

\section{Graph} 
\label{sec:graph}

In this section, we transform the constraint-solving problem into the
reachability in a graph: to find a path in graph where no partial order on the
source and sink exist. 

Transformation ... 
%The insight is consistent with ``A flow model FM is _secure_ if and only if
%execution of a sequence of operations cannot give rise to a flow that violates
%the relation $\rightarrow$''~\cite{denning-lattice}.

% First, for all the constraints in the right-hand-side, we
% first split the constraints into _atomic_ form according to the
% straightforward rules \DZ{only when the lattice is distributive}:
% 
% \[
% \G \proves l_1 \meet l_2 \meet \dots \meet l_m \leq r_1 \join r_2 \join \dots
% \join r_n
% \]
% 
% For constraints in this form, we generate nodes for each side, and
% add one _conditional edge_.
% 
% Static edges?
% 
% Back edges?
% 
% \DZ{No need} Conservative edge. When the right part constrains more
% than one variable, in general, satisfiability would be undecidable. As
% a common practice\DZ{true?}, we conservatively add edges from the
% union node to all variable components.
% 
\section{Ranking}
\label{sec:ranking}

\subsection{Inferring missing assumptions}
\label{sec:assumptions}

\subsection{Inferring likely wrong entities in program}

MAP model

\section{Evaluation}
\label{sec:evaluation}

\subsection{Extensibility}

\subsection{Ranking quality}

\section{Related Work}

\paragraph{Program analyses, constraints and graph} 

Modeling program analyses via constraint solving is not a new idea. The most
related work is set-based constraint program
analysis~\cite{aiken-setconstraint, aiken-typeinclusion}.  However, such
constraints does not model hypothesis, which is important in program analyses
such as information-flow control.
 
Program slicing, shape analysis, flow-insensitive points-to analysis are
amenable to graph-reachability~\cite{reps-graph}. Melski and
Reps~\cite{melski-cflgraph} show the interchangeability between
context-free-language reachability (CFG-reachability) and a subset of
set-based constraints. But only a small set of constraints, namely
only one variable may appear on the right hand side of an partial
order. Moreover, no general error diagnostic approach is proposed on
the graphs to the best of our knowledge. 

\paragraph{Error diagnostic on type inference and information-flow
control} 

Due to the unsatisfactory quality of error reports, a considerable
amount of work have been proposed to improve both error message of
ML-like languages and Jif.

Efforts on improving ML-like language type-error message can be traced back to
the early work of Wand~\cite{wand-errorfinding} and Johnson and
Walz~\cite{johnson-popl86}. These two pieces of work represent two directions
in improving type-error messages: the former one traces _everything_ that
contributes to the error, whereas the latter attempts to infer the _most
likely_ cause. We only discuss the most related among them in this paper. More
details can be found in Heeren's summary~\cite{heeren:thesis}.

In the first direction, many work~\cite{choppella95, haack:slicing,
tip:slicing} follow improves the basic idea of Wand~\cite{wand-errorfinding} in
several ways. Despite the attractiveness of feeding all related details to the
programmer, the reports are usually verbose and hard to follow.

In the second direction, one approach is to alter the order of type
unification~\cite{lee:toplas, mcadam:unification}. However, since error
location may appear anywhere in the unification procedure, any specific order
would fail. Some previous work try to advice the programmer how to fix the
error~\cite{mcadam:thesis, lerner:pldi07}. McAdam~\cite{mcadam:thesis} suggests
using morphisms along with standard type inference to identify potential fixes
of type errors. Lerner et. al.~\cite{lerner:pldi07} try to produce type-error
messages by searching changes to the AST until a program type checks. However,
both approaches are highly specific to the purpose of type inference. There is
no easy way of extending them for information-flow control analysis, for
instance.

For information-flow control, King et. al.~\cite{king:fse} propose to
generate a trace of information flow explaining the information-flow violation
in program. Despite the fact that this approach also diagnoses on a constructed
dependency graph, only a subset of DLM model is handled (hypothesis is not
supported). Moreover, similar to the limitation of type-error slicing,
reporting a whole path can be verbose for programmer.
Merlin~\cite{livshits:merlin} uses probabilistic inference to automatically
infer explicit information flow specifications from program code, an different
application as our paper.

\paragraph{Missing hypothesis inference}

The most related work on inferring likely missing hypotheses is the recent work
on error diagnosis using abductive inference~\cite{dillig:pldi12}. This work
computes small, relevant queries presented to a user that capture exactly the
information a program analysis is missing to either discharge or validate the
error. But it is handling first-order logic and there is no straightforward way
of encoding our constraint language into first-order logic. Also, our
missing-hypothesis inference is more straightforward.

% Automatic instrumentation~\cite{king:esop10}
% Policy inference~\cite{chong:sp11, harris:ccs10}.
% Using statisctical
% analysis for bug finding is not new. Dawson Engler.

\bibliographystyle{abbrv}
\bibliography{constraint,../bibtex/pm-master}

\end{document}
