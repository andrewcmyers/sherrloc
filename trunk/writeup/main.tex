%\usepackage[margin=1in]{geometry}
 
\usepackage{times,graphicx,color}
\usepackage{amsmath, amssymb, stmaryrd}
\usepackage{ttquot,utf8}
\usepackage[comments]{declarations}

\renewcommand{\floatpagefraction}{0.75}
\renewcommand{\dblfloatpagefraction}{0.75}

\title{General Error Diagnostic for Constraint-Based Program Analysis}



\def\sharedaffiliation{%
\end{tabular}
\begin{tabular}{c}}
%


\numberofauthors{2}
\author{
\alignauthor Danfeng Zhang\\
\email{zhangdf@cs.cornell.edu}
%\affaddr{Department of Computer Science} \\
%\affaddr{Cornell University} \\
%\affaddr{Ithaca, NY, 14853}\\
%
\alignauthor Andrew C. Myers\\
\email{andru@cs.cornell.edu}
%\affaddr{Department of Computer Science} \\
%\affaddr{Cornell University} \\
%\affaddr{Ithaca, NY, 14853}\\
%
\sharedaffiliation
\affaddr{Department of Computer Science} \\
\affaddr{Cornell University} \\
\affaddr{Ithaca, NY 14853}
}

\begin{document}

%\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

Nowadays, more and more type systems relies on constraint solving. For
instance, Jif ... Type checking for ML-like language is also by nature
constraint solving. However, it has also been acknowledged for
decades that error diagnostic for such systems are difficult
since the type-checker often reports error locations that are far from the
simplest source of the problem~\cite{wand-popl86}.

%\paragraph{Contributions}

This paper makes the following contributions:

\begin{enumerate}
\item
general representation

\item
application to error diagnosis

\item
evaluation
\end{enumerate}

\section{Model}
\label{sec:model}

\paragraph{Syntax}

The syntax of our general constraint language is formalized in
Figure~\ref{figure:lang:syntax}.

\begin{figure}
\begin{align*}
G &::=\; G \land G\ |\ A \\
A &::=\; C \proves C \\
C &::= C \land C\ |\  E \leq E \\
E &::= x\ |\ c(E_1,\dots,E_{a(c)})\ |\ c^{-i}(E)\ |\ E_1 \join E_2 \
|\ E_1 \meet E_2
\end{align*}
\caption{Syntax of constraints}
\label{figure:lang:syntax}
\end{figure}

The goal $G$ to be solved is a conjunction of assertions $A$ of the
form $C \proves C$, where constraint $C$ on the LHS of the judgement
is the hypothesis whereas $C$ on the RHS is the assertion needs to be
satisfied. Constraint $C$ is simply an conjunction in the form of $E
\leq E$, claiming the partial order on elements $E$. 

Let $V$ be a set of variables and $C$ be a set of constructors. Each
$c\in C$ has a fixed arity $a(c)$. When $a(c)=0$ then $c$ is a
constant. Basic element $E$ contains the variables to be inferred
$x\in V$, constructors $c$ and corresponding destructors $c^{-i}$,
where $c\in C$. For simplicity, we write $c$ for constants. We can
also take the join/meet or elements, which models the least upper
bound/greatest lower bound of two elements in the partial order
respectively. 

Intuitively, the goal is to show that there exists a valuation of
variable such that the right hand side of all constraints can be
satisfied under the hypothesis. We formalize this in the next part.

\DZ{Delete this? When join and meet are used, we assume for all $e_1,
e_2 \in E, e_1 \join e_2 \in E \land e_1 \meet e_2 \in E$ to make the
constraints well-formed. In another word, the elements form a
lattice.}

\paragraph{Solving}

A valuation is a mapping of the type variables to _ground types_,
where ground types form a Herbrand universe.

A goal is satisfiable when there is a valuation s.t. all constraints
are _valid_. Therefore, formally, the goal of this paper is to answer
which element or constraint to blame when a goal is unsatisfiable. A
possible reason may both be the existence of an element or the absence
of one. \DZ{a missing condition (missing where clause) is common in
Jif}

More specifically, $e_1\leq e_2$ iff this partial order can be
inferred under the standard rules for a partial order, namely
transitivity and reflexivity. 

For type inference:

Type inference is reduced to constraint solving by defining a mapping
of _pre-judgements_to constraints:
\[\trans{\G \proves x:\tau} = x =\tau\]
\[\trans{\G \proves \lambda x.e:\tau} = \exists a_1 a_2.
(def x: a_1 in \trans{e:a_2} \land a_1 \rightarrow a_2 =\tau)\]
\[\trans{\G\proves e_1 e_2 : \tau} = \exists a.(\trans{\G \proves
e_1:a\rightarrow \tau}\land \trans{\G\proves e_2:a})\]

\DZ{We may eliminate the $\exists$ by creating fresh variables}

\begin{figure}[b]
\begin{align*}
C &::=\; \tau = \tau\ |\ C \land C \\
\tau &::= x\ |\ \tau\rightarrow \tau
\end{align*}
\caption{Syntax of constraints}
\label{figure:cons:syntax}
\end{figure}

\paragraph{Expressiveness}

Although the core constraint language we proposed is similar to set
constraints~\cite{aiken-setconstraint} in spirit. There are several
noticeable differences:

\begin{enumerate}

\item Most importantly, instead of interpreting $\leq$ as the subset
relation of sets, the partial order is freely defined in the
hypothesis in out language. This extended expressiveness is essential
for modeling real-world type systems, such as the ``where'' clause in
Jif and the subtyping relationship in many object-oriented systems.
Moreover, as we will show in ..., introducing such expressiveness does
not increase the symbolic complicity of our error diagnostic
algorithm.

\item The exclusion of the negation of an element in our model since
it is not essential in modeling the type systems we are aware of.
Also, previous work showed that although solving the full set of set
constraints is decidable, the complexity ranges from NP to NEXPTIME
for non-trivial ground term models~\cite{aiken-complexity}. We believe
that the subset we used in this work is both expressive and practical
for real-world type systems.

\end{enumerate}

Due to the similarity between our core constraint language and set
constraint, the applications modeled by the later without negations
are automatically expressed by our model. Such examples includes type
inference with sum type and product type and closure analysis.
Moreover, our language is also expressive enough to model the
non-trivial DLM model, which is discussed in more detail in next part.

\subsection{Examples}

\paragraph{Jif}

For information flow control, elements are security labels, which in
nature forms a lattice~\cite{denning-lattice}. Join and meet
operations in constraints are consistent with that in the lattice.
$\leq$ is consistent with the partial order in lattice. Some languages
such as Jif allows ``where'' clauses that adding partial orders into
the lattice. The ``where'' clauses corresponds to the hypothesis.  For
other models, the hypothesis is always empty.

In this part, we would focus on the DLM model adopted by Jif, although
other models would be simpler to be modeled.

DLM assumes a set of _principals_ represienting users and other
authority entities. Examples of principals could be student A,
students, teachers and so on. The security concern of information is
expressed by _labels_. A label $L$ contains a set of principals called
the _owners_, $owners(L)$. Owners are the original sources of the
information. For each owner $O$, the label also contains a set of
principals called the _readers_, $readers(L,O)$. Readers are the
principals owner $O$ is willing to release the value. A useful concept
is _effective reader set_ of $L$: the set of principal that is allowed
to read by all owners.

For instance, for label $\{o_1:\ r_1,r_2;\ o_2:\ r_2,r_3\}$, the
effective reader set is just $\{r_2\}$. In a high level, such labels
abstracts allowed flows of the information. For instance, the label
above only allows data from $o_1, o_2$ to $r_2$, but not restricting
the data of other owners.

Such allowed flows are complicated by the _actsfor_ relationship of
principals. For instance, if we know that $r_4$ actsfor $r_2$, then
$r_4$ should also be able to read the data above.

\begin{enumerate}
\item DLM introduces an implicit form of parametric polymorphism, called _label
polymorphism_, to express procedures that are parametric with respect to the
security labels of their arguments.
\end{enumerate}

\paragraph{ML-like language}

Type inference can also naturally map into constraint solving. This
view is not new. For instance, Wand~\cite{wand-typeinference} recast
Hindley-Milner type system into equality constraints. Aiken and
Wimmers~\cite{aiken-typeinclusion} extends the Hindley-Milner type
system with inclusion constraints, and models function types,
constructor types, liberal intersection and union types. Moreover,
with sophisticated systems, constraint solvers are used for dependent
types \DZ{REF}, \DZ{and so on}. In this setting, types are the
elements. Join and meet operations are the usual intersection and
union types if that is well defined.  $\leq$ is consistent with the
subtype relationship between two labels.  Since the definition is
abstract, both syntactic subtyping \DZ{REF} and semantic
subtyping~\cite{aiken-typeinclusion} fit in this model.

\paragraph{Polymorphic Types}

Our model is also powerful enough to capture polymorphic types.  Jif
has polymorphic types, for instance, $caller\_pc$. Polymorphic types
are also crucial for ML-like languages.

Polymorphic types can be naturally modeled in our core constraint
language as follows. For a polymorphic type $t$ instance, we create a
new constant $c_t$ and replace all occurrences of $t$ with $c_t$ in
the constraints. This is sufficient since the semantics of a
polymorphic type is that the constraints should be satisfied
regardless of the value of $t$. For instance, $t\leq \top$ where $t$
is a polymorphic type is satisfiable.

\section{Graph} 

In this section, we formalize the constraint-solving problem into a
graph problem: to find a path in graph where no partial order on the
source and sink exist. The insight is consistent with ``A flow model
FM is _secure_ if and only if execution of a sequence of operations
cannot give rise to a flow that violates the relation
$\rightarrow$''~\cite{denning-lattice}.

First, for all the constraints in the right-hand-side, we
first split the constraints into _atomic_ form according to the
straightforward rules \DZ{only when the lattice is distributive}:

\[
\G \proves l_1 \meet l_2 \meet \dots \meet l_m \leq r_1 \join r_2 \join \dots
\join r_n
\]

For constraints in this form, we generate nodes for each side, and
add one _conditional edge_.

Static edges?

Back edges?

\DZ{No need} Conservative edge. When the right part constrains more
than one variable, in general, satisfiability would be undecidable. As
a common practice\DZ{true?}, we conservatively add edges from the
union node to all variable components.

\section{Related Work}

Set-constraint program analysis~\cite{aiken-setconstraint}.

Using graph reachability as program analysis is also not
new. Program slicing, shape analysis, flow-insensitive points-to
analysis are amenable to graph-reachability program~\cite{reps-graph}.

Interestingly, the equality between context-free-language reachability
(CFG-reachability) and a class of set constraints was also notice
before~\cite{melski-cflgraph}. But only a very restrict set of
constraints, namely the constraints $sexp \leq V$ where $V$ is a
set variable, are considered.

Policy inference~\cite{chong:sp11, harris:ccs10}.

Automatic instrumentation~\cite{king:esop10}.

Previous work on error diagnostic are application specific. For type errors of
ML-like language, slicing is used to identify possible causes of an
inconsistency in type checking. However, the result can be too large to be
useful. Lerner et al.~\cite{lerner:pldi07} propose searching modifications and
ranking the ones passing type checking to provides useful error message. But
this approach is application specific and the performance relies on heuristics. Moreover, the algorithm handles one error per analysis.

Using statisctical
analysis for bug finding is not new. Dawson Engler.

\bibliographystyle{abbrv}
\bibliography{constraint,../bibtex/pm-master}

\end{document}
